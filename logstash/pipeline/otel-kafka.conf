input {
  kafka {
    bootstrap_servers => "${KAFKA_BROKERS:kafka:29092}"
    topics => ["otel-logs"]
    group_id => "logstash-otel-consumer"
    codec => json
    consumer_threads => 2
    poll_timeout_ms => 3000
    auto_offset_reset => "earliest"
    isolation_level => "read_committed"
    enable_auto_commit => true
  }
}

filter {
  # OTLP JSON format: { "resourceLogs": [ { "resource": {...}, "scopeLogs": [ { "logRecords": [...] } ] } ] }
  
  # Parse resourceLogs if present
  if [resourceLogs] {
    ruby {
      code => '
        begin
          resource_logs = event.get("resourceLogs")
          return if !resource_logs || !resource_logs.is_a?(Array) || resource_logs.empty?
          
          resource_log = resource_logs[0]
          
          # Extract resource attributes
          resource_attrs = resource_log.dig("resource", "attributes") || []
          if resource_attrs.is_a?(Array)
            resource_attrs.each do |attr|
              key = attr["key"]
              value_obj = attr["value"]
              
              if key && value_obj.is_a?(Hash)
                actual_value = value_obj["stringValue"] || value_obj["intValue"] || value_obj["boolValue"] || value_obj["doubleValue"]
                
                case key
                when "service.name"
                  event.set("service_name", actual_value) if actual_value
                when "service.version"
                  event.set("service_version", actual_value) if actual_value
                when "service.instance.id"
                  event.set("service_instance_id", actual_value) if actual_value
                when "deployment.environment"
                  event.set("environment", actual_value) if actual_value
                when "host.name"
                  event.set("host_name", actual_value) if actual_value
                when "telemetry.sdk.language"
                  event.set("sdk_language", actual_value) if actual_value
                end
              end
            end
          end
          
          # Find the first non-empty logRecords array in scopeLogs
          scope_logs = resource_log.dig("scopeLogs") || []
          log_record = nil
          
          if scope_logs.is_a?(Array)
            scope_logs.each do |scope|
              records = scope.dig("logRecords") || []
              if records.is_a?(Array) && !records.empty?
                log_record = records[0]
                break
              end
            end
          end
          
          return unless log_record
          
          # Extract log body
          log_body = log_record.dig("body")
          if log_body.is_a?(Hash)
            event.set("message", log_body["stringValue"])
          elsif log_body
            event.set("message", log_body.to_s)
          end
          
          # Extract severity
          severity_text = log_record["severityText"] || "UNSPECIFIED"
          event.set("log_level", severity_text)
          
          # Extract timestamp - Logstash expects @timestamp as an ISO8601 string
          time_unix_nano = log_record["observedTimeUnixNano"] || log_record["timeUnixNano"]
          if time_unix_nano && time_unix_nano.to_i > 0
            begin
              time_seconds = time_unix_nano.to_i / 1_000_000_000.0
              time_obj = Time.at(time_seconds).utc
              # Logstash accepts ISO8601 strings for @timestamp
              event.set("@timestamp", time_obj.iso8601(9))
            rescue => e
              event.set("timestamp_error", e.message)
            end
          end
          
          # Extract log record attributes
          log_attrs = log_record["attributes"] || []
          if log_attrs.is_a?(Array)
            log_attrs.each do |attr|
              key = attr["key"]
              value_obj = attr["value"]
              
              next unless key && value_obj.is_a?(Hash)
              
              # Special handling for kvlistValue (extra_fields, etc)
              if value_obj["kvlistValue"]
                kv_list = value_obj["kvlistValue"]["values"] || []
                if kv_list.is_a?(Array)
                  kv_list.each do |kv|
                    kv_key = kv["key"]
                    kv_value = kv["value"]
                    if kv_key && kv_value.is_a?(Hash)
                      actual_val = kv_value["stringValue"] || kv_value["intValue"] || kv_value["boolValue"]
                      safe_kv_key = kv_key.gsub(".", "_")
                      event.set(safe_kv_key, actual_val) if actual_val
                    end
                  end
                end
              else
                # Standard value extraction
                actual_value = value_obj["stringValue"] || value_obj["intValue"] || value_obj["boolValue"] || value_obj["doubleValue"]
                
                if actual_value
                  safe_key = key.gsub(".", "_")
                  event.set(safe_key, actual_value)
                end
              end
            end
          end
          
        rescue => e
          event.set("parse_error", e.message)
        end
      '
    }
  }

  # Skip empty messages
  if [message] == "" or ![message] {
    drop {}
  }

  # Clean up - remove ALL nested/complex structures that may cause mapping issues
  mutate {
    remove_field => ["resourceLogs", "[@version]", "event", "extra_fields", "scopeLogs", "timestamp_error"]
  }
}

output {
  elasticsearch {
    hosts => ["${ES_HOST:elasticsearch}:${ES_PORT:9200}"]
    index => "otel-logs-%{+YYYY.MM.dd}"
    manage_template => false
  }

  # Debug output
  stdout {
    codec => json_lines
  }
}
