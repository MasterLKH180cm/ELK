extensions:
  health_check:
    endpoint: "0.0.0.0:13133"

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: "0.0.0.0:4317"
      http:
        endpoint: "0.0.0.0:4318"
  
  # OHIF Logs
  azureeventhub/ohif:
    connection: ${env:AZURE_EVENTHUB_CONNECTION_STRING_OHIF}
    format: "azure"
    # partition: "0" # Optional: set if needed for high throughput
    # offset: "@latest"

  # Dictation Backend Logs
  azureeventhub/dictation_backend:
    connection: ${env:AZURE_EVENTHUB_CONNECTION_STRING_DICTATION_BACKEND}
    format: "azure"

  # Dictation Frontend Logs
  azureeventhub/dictation_frontend:
    connection: ${env:AZURE_EVENTHUB_CONNECTION_STRING_DICTATION_FRONTEND}
    format: "azure"

processors:
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  resourcedetection:
    detectors: [env, system]
    override: false

  # Add attributes for routing and identification
  transform:
    log_statements:
      - context: log
        statements:
          - set(attributes["log.level"], severity_text)
          - set(attributes["event.domain"], "default") where attributes["event.domain"] == nil
          
          # Tag Azure sources based on scoping (receivers will tag via resource processors if possible, but here we can't easily distinguish receiver in transform unless we use separate pipelines with resource processors)
          # Better approach: Use resource processors in distinct pipelines. See 'service' section.

  # General attributes batching
  batch:
    send_batch_size: 256
    timeout: 2s
    send_batch_max_size: 1024

  # Resource processors for each pipeline to tag source
  resource/ohif:
    attributes:
      - key: event.domain
        value: "ohif"
        action: upsert
      - key: service.name
        value: "ohif-service"
        action: upsert

  resource/dictation_backend:
    attributes:
      - key: event.domain
        value: "dictation-backend"
        action: upsert
      - key: service.name
        value: "dictation-backend"
        action: upsert
  
  resource/dictation_frontend:
    attributes:
      - key: event.domain
        value: "dictation-frontend"
        action: upsert
      - key: service.name
        value: "dictation-frontend"
        action: upsert

  # Filter processors for internal routing (if needed to prevent cross-talk in default pipeline)
  # But with separate pipelines, we don't strictly need complex filters.

exporters:
  debug:
    verbosity: basic

  kafka/traces:
    brokers:
      - kafka:29092
    protocol_version: "2.6.0"
    client_id: "otel-collector-traces"
    topic: otel-traces
    encoding: otlp_json

  kafka/metrics:
    brokers:
      - kafka:29092
    protocol_version: "2.6.0"
    client_id: "otel-collector-metrics"
    topic: otel-metrics
    encoding: otlp_json

  # Exporters for specific log domains
  kafka/logs-ohif:
    brokers:
      - kafka:29092
    protocol_version: "2.6.0"
    client_id: "otel-collector-logs-ohif"
    topic: otel-logs-ohif
    encoding: otlp_json

  kafka/logs-dictation:
    brokers:
      - kafka:29092
    protocol_version: "2.6.0"
    client_id: "otel-collector-logs-dictation"
    topic: otel-logs-dictation
    encoding: otlp_json

  kafka/logs-default:
    brokers:
      - kafka:29092
    protocol_version: "2.6.0"
    client_id: "otel-collector-logs-default"
    topic: otel-logs-default
    encoding: otlp_json

service:
  extensions: [health_check]
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, batch]
      exporters: [debug, kafka/traces]

    metrics:
      receivers: [otlp]
      processors: [memory_limiter, resourcedetection, batch]
      exporters: [debug, kafka/metrics]

    # Pipeline for OHIF (EventHub)
    logs/ohif:
      receivers: [azureeventhub/ohif]
      processors: [memory_limiter, resource/ohif, batch]
      exporters: [kafka/logs-ohif]

    # Pipeline for Dictation Backend (EventHub)
    logs/dictation_backend:
      receivers: [azureeventhub/dictation_backend]
      processors: [memory_limiter, resource/dictation_backend, batch]
      # Using shared dictation topic or could split further. Let's start with shared 'otel-logs-dictation'
      exporters: [kafka/logs-dictation]

    # Pipeline for Dictation Frontend (EventHub)
    logs/dictation_frontend:
      receivers: [azureeventhub/dictation_frontend]
      processors: [memory_limiter, resource/dictation_frontend, batch]
      exporters: [kafka/logs-dictation]

    # Pipeline for General OTLP Logs (Browser/FastAPI)
    # These usually carry their own attributes, just pass through to default or route if needed
    logs/default:
      receivers: [otlp]
      # We rely on the app to set attributes. If we want to route based on attributes, we need the Routing Processor or multiple exporters with filters.
      # For now, dump to default log topic, Logstash can sort it out, OR we can route here.
      # Given the user request for optimization, let's keep it simple: dump to otel-logs-default
      processors: [memory_limiter, resourcedetection, transform, batch]
      exporters: [kafka/logs-default]